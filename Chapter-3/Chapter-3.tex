\chapter{AUDIENCE PARTICIPATION EVALUATION: SETTING, METHODOLOGY AND METHODS}
\label{chap-three}

Sample editing task made in the new branch in the forked project for Ellie.

This chapter details the methodological design and methods used to conduct this research in order to answer the following research questions outlined in the previous chapters:
\begin{enumerate}
  \item How do technical communicators learn about their audiences?
  \item How can we read audience interactions from the content that we have, generated by them, through their interactions with documentation platforms?
  \item How do new contextualizations of audience change the work expected of technical communicators?
\end{enumerate}
In the past, many technical communication scholars have studied audience contributions to collaborative knowledge production platforms such as user forums \cite{swarts2007mobility, frith2017forum}, feedback on public websites such as blogs \cite{gallagher2020update}, and interactions with social media posts \cite{breuch2018involving}. Since these works were published, audiences have changed drastically, especially in the software documentation field, and these studies do not fully help contextualize them. The research questions mentioned above seek to not only extend such work but also to contribute to the growing scholarship on audience analysis in the technical communication field by analyzing newer sites of study.

The goal of this research is to study user interactions with content. User interactions lie on a spectrum from active to passive. This research attempts to demonstrate how these interactions reveal something about audiences that can and should influence how technical communicators interact with audiences and handle content. The research was conducted in two stages: first, a mixed-methods approach was used to conduct interviews with practitioners in the technical communication field and to analyze the themes in those interviews. The interview data led to various sites of user interactions that result in knowledge production. Three sites were picked as case studies for this research: first, a pull request on GitHub that results not only in content creation by users, but also a back-and-forth communication channel to improve content and make it more usable. Second, data from content analytics tools that track user engagement on the documentation interface of a new product. The findings from this data reveal users' needs and are used to address them in a more effective and timely manner. The third (and final) case study looks at the  feedback mechanism that provides users with access to the organization's internal ticketing tool to create issues/tickets for the documentation team to handle. The second stage of this research study was the \textit{analysis} phase that consisted of a qualitative analysis of those sites or selected case studies to reveal the complex networks of people, technologies and technical communication roles that not only mediate knowledge development in software documentation spaces, but also lead to a more inclusive contextualization of audiences. Each of the case studies are different, and represent typical models of how audiences interact with content as shared by practitioners during the interview phase. The results of the analysis phase are described in the next chapter (Chapter \ref{chap-four}). The following sections provide a detailed account of the process of data collection (which will also provide a rationale for selection of the sites of study) and also the methodological framework used for analysis.

\section{User interactions}
For the purpose of this research I define a user interaction as a social (organizational) and functional network that gets created when a user comes into contact with an information system's interface. Since 1998 when Johnson proposed that users should be treated as producers of knowledge, scholars have explored the ways in which technical communicators can participate in distributed knowledge activities by recording user interactions and making sense of user contributions in knowledge development processes.  Although scholars have studied user interactions in the technical communication field, most of the research tracks \textit{visible} user contributions.  As the genre of information products in the field of technical communication is expanding, so are the means for users to interact with content. Chapter \ref{chap-two} demonstrated the need to analyze interactions on a continuum.In this research I sought to understand the more \textit{invisible} ways of user interactions with content and their impact on technical communicators' roles. To identify such invisible ways, technical communication practitioners who designed or utilized systems that record user interactions were interviewed. The interview process is described in the next section.

\section{Interviews and participant selection process}

Long-form interviews were used for data collection in this research. Scholars have used this method to investigate topics such as coworking \cite{spinuzzi2012working}, and entrepreneurship in technical communication \cite{lauren2016networking}. I chose to focus my data collection and research in the computer and software industry. Apart from my experience and industry partnerships built over several years in these fields, this choice was dictated by the significant amount of technical communication and user research in the technology industry that this research could contribute to. The case studies, while being picked through a convenience sampling method, are not only typical for the software field, but are gradually becoming popular in other industrial sectors as well \cite{docsascode} (https://www.writethedocs.org/guide/docs-as-code/).

The presence of this audience phenomenon being in the software industry for a sustainable time provides reasons for using the aforementioned cases for this study. The IT revolution in the late 1980s gave rise to the need to publish product documentation online (web-based). Businesses became more globally distributed and teams no longer worked in the same location. Software industries quickly adopted new technology and approaches to allow collaboration among remote teams. Therefore, practices such as structured content and Agile became more prevalent in software industries. Since it was possible to develop, implement, and maintain technological solutions required to complement these approaches completely in-house, software companies became quick adopters as well as leaders in legitimizing these approaches. Similarly, the docs-as-code or open authoring approach, which motivated this study (see Chapter \ref{chap-one}), also started in the software industry and is mostly popular in the same field. Additionally, studies such as Techwhirl (Document 360) show that over half of the employed technical communicators in the US work in technology-related fields. The U.S. Bureau of Labor Statistics’ employment projections show that a majority of writers from 2019-2029 will be hired by the Professional, scientific, and technical services industry. These reasons not only make studying cases from the software industry more important, but ensure that results of this research will be applicable to the current industrial scene.

Participants from software companies were recruited using a targeted selection followed by a chain referral system to recruit even more participants. First a list of technical communicators’ names and contact information was created based on my experience of working with them in their respective organizations (during past internships or collaborative projects), or peer-referrals from other employees (except supervisors) who have known their work. I also scanned public profiles (such as social media sites like LinkedIn, Twitter  \& professional websites) of potential participants who had desirable characteristics based on the stated experience on those platforms. I also publicized the study through a podcast to gain interest from technical communicators in the field. About 60\% interview participants were recruited using this system. The remaining 40\% were recruited through a chain-referral system, that is, initial subjects were asked during the interview to identify peers that would be able to make relevant contributions and also be interested in participating in this study. During recruitment, information about the research goals and research process was shared with potential participants over email. If they agreed to the interview request, they were asked to sign a consent form, and share their availability for interviewing. Based on participants’ availability, interviews were scheduled for one hour each and questions were shared in advance. All interviews took place over Zoom. Interviews were recorded and transcribed before being analyzed for identification of case studies.

The interview process for this study was semi-structured \cite{dicicco2006qualitative, knox2009qualitative, glaser2017discovery}, that is, the questions lay somewhere between completely structured (or standardized) and completely unstructured. The goal of structured interview questions is to expose all participants to exactly the same interview experience \cite{fontana2005interview} so that any differences are assumed to be due to variations among participants rather than to differences in the interview process itself \cite{fontana2005interview}. A list of 10 structured questions (listed below) was made to ask technical communication practitioners about the practices in which they learn about their audiences and record audience interactions, as well as their roles in the company apart from writing documentation content. The motive of interviews was to see what contexts of the audience where they engage with content, should be studied more closely. And how writers manage or access content created through such interactions.
\begin{enumerate}
  \item Do you develop content collaboratively for internal/external documentation?
  \item Can you describe your role as at <organization name>?
  \item Do you have access to users of the project/s you work on either through usability tests, content development processes, analytical software or any other means?
  \item How do you solicit contributions from internal and/or external entities?
  \item Do interactions with users generate content? Is that content used? How do you handle that content? Do users know that they can participate in content development?
  \item If yes for content development processes, can you describe the process in detail. How can users participate? How is the content moderated? How many stakeholders are involved?
  \item What does the publishing process look like from the time they contribute to inclusion or exclusion in released docs?
  \item What other tools are involved in the process? Are the users/contributors familiar with them?
  \item How long have you been working with projects that use participation from the community of users? Do you think it has changed the role of business and/or professional communicators?
  \item How do you manage collaborative projects? (Methodology – agile/kanban/scrum/scaled agile/waterfall).
\end{enumerate}

Unstructured interviews mostly consist of open-ended questions. Sometimes they start with a single topic-introducing question and the remainder of the interview proceeds as a follow-up and expansion on the interviewee’s answer to the first questions \cite{kvale19961}. After learning about their practices, open-ended questions were asked to follow-up and document as many details about the process of content generation and its inclusion into the official technical documentation as possible. The motive of open-ended questions was to understand different organizational processes and components involved in enabling audiences to interact with information platforms and writers' role in facilitating those interactions. This portion of the interview can be considered as the unstructured one. Participants were also questioned to understand technical communicators’ responsibilities during this process. Every interview was thus designed to be semi-structured, non-linearly moving from structured and unstructured questions.

In total, 19 interviews were conducted. The participant pool consisted of employees who worked for 9 different software companies who all identified themselves as technical communicators and played roles such as writers, technical communication managers, content strategists, data analysts, information developers, information designers of technical communication teams. On an average interviews lasted for approximately 40 minutes (total interview time: 566 minutes). All participants were asked the same set of questions. In cases where data was uniquely relevant to the research, or if responses were not completely clear in terms of providing details of the organizational processes, follow-up questions were asked. As mentioned earlier, the chain referral system was used to recruit more participants after the preliminary interviews. After 13 interviews similar data patterns were observed. So I decided to terminate the interview process. At that point, all interview recordings were saved in a secure location and transcribed to identify viable case studies. A closer analysis of the transcribed interview data revealed that there were over 13 practices in which audiences interacted with documentation platforms and each of those practices could be used to learn about audiences. Since it was almost impossible to analyze all 13, I boiled my research to 3 of the most used yet under researched practices. I have decided to save some of the others for my future research.

Although the interview sample size might seem small, I hit a saturation point in terms of the variety of data that I could derive from interviews after completing the first 19. Saturation is defined by many as the point at which the data collection process no longer offers any new or relevant data \cite{dworkin2012sample}. There is a variability in expert opinions on what is a minimum number of interviews required for a study like this one. A large body of literature suggests that anywhere from 5 to 50 participants is adequate. Most scholars argue that the concept of saturation is the most important factor to think about when mulling over sample size decisions in qualitative research \cite{charmaz2006constructing, dworkin2012sample}. In this study, I noticed a saturation when the discussions (interviews) with practitioners revealed similar tools and practices used by them to collect user inputs in the documentation development and publication process. The snowball method allowed me to analyze the data soon after collecting it helping me detect saturation early on in the process. Participant demographics was another criterion that was overlooked. Charmaz \cite{charmaz2006constructing} suggests that other key stratifiers are only critical if they provide an in-depth understanding of the topic being examined. As demographics of technical communicators do not impact user contributions, participants who worked in technical communication roles were noted as designations, but treated similarly.

\section{Results of analyzing interview data}
As mentioned earlier, three practices were picked from the total of 13 practices that were revealed in the interview data. This section describes the process for choosing them.

\begin{figure}[t]
  \begin{center}
      \includegraphics[width=1\textwidth]{Chapter-3/figs/interview_results_1.png}
  \end{center}
  \caption{Practices to record audience interactions}
  \label{fig:ch3.1}
\end{figure}

The interview data were transcribed and then coded based on different themes. Two broad themes were quantitative and qualitative. Qualitative methods were further broken down based on the nature of content being produced by audiences. For example, pull requests on GitHub, and translated content on repositories (created using a crowd-sourced system) were classified as content contributions; on the other hand, back-and-forth messages like those on support calls (support personnel and any user on a one-to-one communication channel), posts on Slack (organization’s communication tool), and emails, user forum posts, and other messages were all classified as social media practices. Figure \ref{fig:ch3.1} shows all the 13 practices revealed from the interview data.

There were four important criteria used to choose the 3 practices or case studies from these 13 – first, the data to link cases to the propositions \cite{Campbell_2000} that motivated this research. The theoretical predilection for this research was that users' roles were evolving from content consumers to content producers in turn impacting technical communicators' roles on how they handled not just the content, but also the processes leading to content/knowledge development. Preliminary fieldwork demonstrated content generation on versioning systems like GitHub which became the key motivation; the process to create a pull request on GitHub became an important consideration (see Chapter \ref{chap-one}) and opened the perspective on what to ask the participants so that they can reveal similar cases in their content development processes \cite{Campbell_2000}. Second, literature was consulted to define each case study, especially to generate ideas that would help establish the purpose of the research \cite{Campbell_2000, Rashid_Rashid_Warraich_Sabir_Waseem_2019, Yin_1994}. As noted in Chapter \ref{chap-two}, studies on audiences so far have primarily focussed on dichotomies and the purpose of this research is to provide approaches to study the continuum by understanding contextual information about user contributions which lies on a spectrum of passive to active interactivity. Each case was analyzed using the lens of continuous collaboration between audiences and technical communicators that enabled users’ participation as well as helped record processes to understand their contributions closely. The definitions of case studies then helped draw empirical data associated with each case study to understand the social, user oriented phenomenon in the documentation production process. Third, to collect such empirical data it was important to choose participants corresponding to case studies who would be willing to be consulted on multiple occasions to understand the social phenomenon in detail \cite{Rashid_Rashid_Warraich_Sabir_Waseem_2019}. The last criteria was the ability to make analytical generalizations from the case studies applicable to the broader field. Case studies make it possible to study social phenomena by identifying essential factors, processes, and relationships. \textcite{Yin_2017} and \textcite{Campbell_2000} argue that unlike laboratory experiments that are pursued to find a new, remarkable phenomenon, case studies should be used as representative samples that will shed empirical evidence to demonstrate a theory that can be applied to common processes in the field. The case studies picked for this research are therefore based on what can be considered “typical” in the field of technical communication, likely to achieve generalizable findings. Typical for this research are cases that are frequently occurring phenomena across multiple technical communication environments, which may have some commonalities in the way it is set up, but different in terms of how it may be interpreted or used by technical communicators across all organizations. In this research, case studies will primarily be used to contribute to  theory building about audiences, to analyze other concrete situations engaged in knowledge building in the technical communication field, and to predict future trends that can be applied to technical communication practice.

\section{Defining case studies}
\textcite{Yin_1994} defines case study as an empirical research activity that, by using versatile empirical material gathered in several different ways, examines a specific event, series of events, or action in a bounded environment. The objective of examining a case study is to do intensive research on a specific case by identifying essential factors, processes, and relationships between all actors who participate in the construction and working of the case study site. Case study research consists of a detailed investigation with empirical material collected over a period of time from a well-defined case to provide an analysis of the context and processes involved in the phenomenon. The context and phenomenon are not disconnected, but rather the context is responsible for making the phenomenon interesting for study. In the case studies chosen for this research, the phenomenon is user interactions producing content. Since the process for content generation may not always be linear, the starting and ending point of the content generation process have been defined to isolate the case and get a cogent, end-to-end and definite contextualization.  This section describes each case study based on the end points of the processes involved in the case study, actors involved, interactions between actors, outcomes of the process, the data gathered, practices for collecting data, and the theoretical frameworks used to understand and analyze it.

The goal of using three case studies is not to compare or contrast between them, but rather to provide a heuristic way of reading audience engagement. Following are descriptions of each case study:

\subsection{Creating pull request on GitHub}
The first study is that of a pull request also known as merge request on GitHub (Figure \ref{fig:ch3.2}). GitHub is a platform used by several companies to publish their online documentation. User's create a pull request to suggest a change or an update to the documentation topic published. For this research, a pull request is regarded as a notable user interaction.

\begin{figure}[t]
  \begin{center}
      \includegraphics[width=0.5\textwidth]{Chapter-3/figs/pull-request-block.png}
  \end{center}
  \caption{Block diagram of the pull request process}
  \label{fig:ch3.2}
\end{figure}

The term pull request is used for version control platforms only where users send a request for something to the creators or managers of the project involved. GitHub is set up on Git, a version control system, which also acts as a database or repository to store (data, code, and/or) content. Essentially it maintains all copies of source code, files, or any other content that is staged on it. Additionally, GitHub offers access control and several collaboration features such as bug tracking, feature requests, task management, continuous integration and wikis for every project. Conventionally, users left their comments on online documentation platforms such that the comments were visible to the public. The technical communicator associated with the product (and thus the product documentation of that page) responded to the comment and/or incorporated the user's feedback to improve and update the content on that page in their own way. Platforms like GitHub provide users with access to the backend or server-side of the documentation website which they can use to propose the change they want. The backend is responsible for storing and organizing content and also holds code that manages the look and feel of the content published (frontend). Although the backend is not visible to the users when they are viewing content, they can use the "Edit" button to enter it. This is a key component of the process of recording user interactions (Figure \ref{fig:ch3.2}). Unless users click the button, they don't have the tools to provide feedback in content form. The backend and frontend are usually connected such that the backend communicates with the front-end, sending and receiving information to be displayed as a web page (cite). However, in documentation platforms where users can give their feedback or request change by entering the backend to make the change, another layer – staging server, is placed between the published content and editable content backend (Figure \ref{fig:ch3.2}).

To summarize, in the case of a pull request, to propose a change or leave feedback that requires changing the content directly, users first click on the Edit button, enter the backend space where they get access to various tools to make necessary content updates including writing a comment for managers of the content, and submit a pull request to notify the managers asking them to accept the change to improve the content, resolve a problem with the content, or raise an issue. This method can be categorised as a hybrid feedback mechanism (between invisible and visible) since users can see the content they create, but the input may not necessarily be publicly visible. Other users can only view the content added if they open the backend as well.

\subsection{Collecting data from web analytics tools}
Another common tool to record user interactions is a data analytics platform like Google Analytics (GA). As users interact with content on the online documentation website, web analytics scripts running in the background of the website record user activity and collect data points that enable technical communicators to check metrics, spot trends, and identify content that audiences spend time viewing (Figure. \ref{fig:ch3.3}). Web analytics is the measurement, collection, analysis, and reporting of web data to understand and optimize web usage. Web analytic scripts collect user data in an invisible manner.

\begin{figure}[t]
  \begin{center}
      \includegraphics[width=0.5\textwidth]{Chapter-3/figs/web-analytics-block.png}
  \end{center}
  \caption{Block diagram of process for using web analytics data}
  \label{fig:ch3.3}
\end{figure}

In most cases, users don't have access to the data recorded from their interactions on the documentation websites stored on the web. The Google Analytics interface is full of useful data and valuable insights, providing multiple ways to visualize data including tabular reports (default), pie charts, pivot tables, comparison charts and performance charts (Figure \ref{fig:ch3.3}). The various report types allow technical communicators to dive deeper into understanding customer behavior. For example, traffic or site visit reports provide an immediate picture of online documentation traffic with respect to the source of traffic, number of views per page, bounce rate (how many users spent less than 10 seconds on the page), etc. On the other hand, audience reports help categorize users based on their demographics and levels of engagement. Such insights can help to inform information design and content strategy of the site.

A large number of interview participants mentioned the use of data analytics to understand user behavior (\~ 60\%). This case is retrieved from a company's approach of using data analytics in combination with additional data retrieved through other sources to make sure that documentation is effective and successful at resolving users' problems. In this case, Google Analytics is the primary tool used to record users' movements on the online documentation site. Google Analytics in this case was configured to record page views, average time on topic pages, bounce rate, and the actual amount of time spent on page. The main requirement to record this data is that users interact with the webpage. If they don't, no data will be recorded. In order to make sense of the recorded data, the technical communication team at this company, paired the Google Analytics data with other data sources (Figure \ref{fig:ch3.3}). The company uses a combination of Google Analytics with Pendo – to record user interactions with the product interface, Salesforce – to trace support tickets that refer to issues relevant to the topic on the corresponding product documentation page with useful data analytics, and Feedback comments – qualitative feedback on the website stated by product stakeholders(Figure \ref{fig:ch3.3}). For this case study, users interactions that result in production of data that gets recorded by Google Analytics will be considered. However, the process to make sense of that data, as related to data from the other tools will also be considered to study the knowledge network thus formed.

\subsection{Reporting errors in documentation}
The last case study is the error reporting tool provided to users through the documentation website. Users interact with documentation platforms to report errors that they encounter when they use documentation. The company from which this case is derived uses two practices to enable users to submit errors.

\begin{figure}[t]
  \begin{center}
      \includegraphics[width=0.5\textwidth]{Chapter-3/figs/errors-block.png}
  \end{center}
  \caption{Block diagram of error reporting process}
  \label{fig:ch3.4}
\end{figure}

First, GitHub Issue reporting tool, and second, a feedback form set up by the organization on the product documentation platform used to specifically report errors (Figure \ref{fig:ch3.4}). Both practices end up creating an issue or ticket on the company's internal issue tracking tool called 'Jira'. Jira is used for issue tracking and project management by many organizations. It enables employees to create issues, assign them to team members, set priority for resolution of the issue, and so on. In this case, users click on the feedback tool to create an issue, or open the topic on GitHub (backend), and fill required parameters to create an issue or ticket for the technical communicators to solve.

As users click the link to create the issue on the product documentation page a window gets displayed with open text boxes asking the user to insert a title and description of the issue (Figure \ref{fig:ch3.4}). The URL of the topic page gets recorded by default. Once the user submits the request, an issue gets recorded in the company's Jira portal, and the technical communicator, technical communication manager and product manager, all get notified via email linking it to the Jira instance. This method can also be categorized as a hybrid. Issues on GitHub can usually be viewed by other users, but issues entered in Jira may not be visible to stakeholders outside the organization (Figure \ref{fig:ch3.4}). Once users enter the issue, they may lose all control over the content as it gets transferred to the organization and can be modified by authorized personnel only.

\section{Factors for analytic generalizations}
The three case studies are important practices of collecting evidence about users' needs and concerns about documentation. However, these practices still remain under-researched in the technical communication field. The little research on them helps us address concerns of content strategy and information design. These case studies were not experimental, but rather collected from common experiences of technical communicators working in software companies. Therefore, we can assume them to be typical and representative specimens of audience interactions with technical documentation content. Although the goal of this research is to analyze these case studies to answer the research questions, I also wanted to list the distinctive features of these case studies which make them representative of similar cases in the field in general. This will especially be helpful in applying analytic generalizations of the findings of this study to the broader technical communication field. The following factors thus help to delineate the similarities of these cases while also helping establish the commonalities and implications of studying these cases for the field. 

\subsection{Networked structure}
Each of the cases can be studied from a network perspective. Many technical communication scholars have time and again proved that interpreting discourse requires understanding the social context in which it is produced and used. One way to do so is looking at the framing of discourse communities that lead to knowledge production. In their article, Miller and Selzer analyzed rhetorical conventions to separate knowledge producers that form those discourse communities \cite{miller1985special}. They classified them based on generic, institutional, and disciplinary conventions that correspond to the roles that content producers play in engineering institutions. When we add users to the knowledge production space, we need to look beyond such definitive conventions. \textcite{nardi1996context} proposed a sociocultural approach that allows researchers in neighbouring fields such as human computer interaction and computer-supported cooperative work to study complex situated contexts while producing findings that are generalizable (p.70). To study the content produced by individuals and groups in everyday work situations we need to understand the contexts of the particular communities in which the content was created \cite{miller1985special}. One way to study those situations is to analyze the rhetorical conventions of creating technical discourse. But separating communities by the role they play is not enough. Maggiani studied the more social nature of technical communicators' work as they engage in  "a collaborative effort, combining the knowledge of all [associated] participants in a many-to-many communication to produce content which then results in new genres of  technical communication \cite{maggiani2009cloud}. Based on these studies, one way to look at the case studies and audience interactions is to study the network of participants responsible for contributing content in some way or another. In each case, a network of human and non-human actors is created and dynamically reconfigured each time a user interacts with the documentation platform. Networks of participants are created and destroyed to contribute to data that can be used for audience contextualization and knowledge creation occurs in dynamic, flexible, and reconfigurable networks of employees \cite{castells_2020} that extend widely within and beyond the organizations' employees.

\subsection{Visibility}
During the interviews, participants noted that technologies were important for how they solicit user interactions that results in collection of data. Although the role of technology is evident in each of the situations, the work of content creation is not always visible. For example, the "Edit" button on the GitHub page leads to users' contributions to content, but the backend where content is actually being altered is not visible on the documentation platform. web analytics used to record audience journeys on the documentation platform are not visible to anyone except the managers of the content platform. Results of analyzing these cases can therefore be generalized for both visible and invisible contributions of data in knowledge development processes.

\subsection{Outcome of interaction}
Another characteristic crucial for this study is the transformation of user interactions into data or content. Similar to networks being reconfigured for the purpose of soliciting user contributions, the infrastructure and tools used to record those interactions transform content created by users into forms that can only be interpreted through a specialized system of interpreting the content. For example, while user movements across documentation may help them navigate different topics that will help them use the software product in an efficient manner, web analytics may record the search terms, topics they visited before arriving at the topic that resolved their problem, and the time they spent to read the topic while solving their problem. In this manner, user activities get transformed into data which can then be used to design the content strategy, decide metadata of the content page, and so on. This research will analyze each case to factor in the transformations of content from the moment of user's interaction, the method of storing the transformed content, and the implication on technical communicators' decision making process.

Although each of the case studies is a different framework with different actors doing different actions, these common characteristics will help us understand audiences through generalizable findings.

\section{Uncovering audience networks}
This section describes the process of data analysis in order to answer the research question – "How can we read audience interactions from the content that we have, generated by them, through their interactions with documentation platforms?"

The main objective of this research is to observe case studies where audiences are studied as being one category of actors involved in co-creation of knowledge within the product documentation development network, which in turn provides insights about them, such as their needs and other characteristics. The approach, of acknowledging audiences' role in the knowledge networks to study audiences, is unique and has not been explored in the field of technical communication. The focus is not on the outcome of interactions, but rather the process of interacting and responding to interactions. From an empirical and analytical point of view, ANT is one of the theories used by researchers who are interested in analyzing such processes where actors in networks are assembled and maintained in place. ANT enables researchers to understand how actors are enrolled in new programs of activity and prevented from following their own designs in similar processes. Hence, Actor Network Theory is used in this research as the primary theoretical framework to understand audiences' role and interactions on documentation platforms that result in content development. The interactions and related processes are studied as being an outcome of social constructions \cite{lincoln2011paradigmatic}.

This research uses a mixed-methods qualitative approach. Empirical data were used to identify cases that will help contextualize the understanding of audiences in technical communication. Theoretical approaches were used to analyze case studies to establish a new understanding of audience analysis methods. The objective of using theoretical approaches was to start the analysis process by looking at the actors participating in the networked content production process. The study depends on the interpretations derived from case studies' data and the validity checks performed in order to ensure that the analyses can be practically used for future approaches. While it was important to start tracing all the social actors in each case study, it was also crucial to set boundary conditions on the extent of interactions being studied.

\subsection{Boundary conditions}
A lot of earlier work that looks at audience analysis, approaches it from the lens of empirical research methods so that data remains fixed. For example, data created by audiences such as in social media, blogs, forums, etc. analyzed to understand audience needs can be limited by some sort of stopping-criteria such as duration of time, or quantity of messages. Such criteria are not useful for analyzing case studies identified for this research as the content created is not uniform. Therefore, this research begins by analyzing the role of one primary actor and tracing the network of content creation thereafter. Two main criteria drove the analysis process:

\begin{itemize}
  \item A starting point: A starting point was defined as the instant at which the user interaction took place. Instead of looking at more than one generalized case to identify a pattern across multiple similar cases, each of the case studies denotes a typical case of user interaction and the moment of interaction was initiated as the starting point. The process, chronology of next steps, and other dependent processes were based on this starting point.
  \item Stopping condition: Process analysis can be a never-ending journey without a predefined endpoint or an assumed stopping condition. For this research, the stopping condition was defined as the moment when the process network was stabilized, that is, it returned to the conventional state.
\end{itemize}

For example, in case of Twitter, or any other social media platform, content, once placed, remains static on the platform's surface, until a user interacts with it. If a user clicks the like button on a Twitter post, the user interface changes, several other actions are triggered to first, fill color (red) in the heart icon (like button), display the user's name as a user who like the tweet on the tweet dialog, send notifications to the user's network about the user's interaction, and so on. While these tasks are processing, the network of chain reactions can be said to have destabilized as compared to the initial steady state. Each case study has been analyzed from the user's interaction that leads to the unsteady state, until it is stabilized again by the network of actors working towards that goal.

That also means that this was not designed to be an indefinite study. Although there can be infinite actors that form the knowledge network, data were only retrieved from one instance of interaction that produced content in each case, until the network was stabilized and/or content was translated \cite{callon2007some}. Additionally, knowledge networks in larger organizations are fluid, owing to constant evolution, re-organization and transformations in roles and procedures used by actors at large organizations. As an attempt to keep the study definite, relevant, and within the context of technical communication, only the actors that became part of a network as a result of those audience interactions were considered, and new actors were added until the point of content transformation, thus helping to set the scope of this project. Three steps were necessary to trace networks:

\begin{enumerate}
  \item Analyze a network and begin by identifying the primary actor at the moment of interaction.
  \item Identify subsequent actors and their associations with the previously detected actors.
  \item Analyze how new relationships were built or exercised in an attempt to force the network to return to its conventional state.
\end{enumerate}

To trace the interactions for the Twitter example, the chronology of events becomes important. As mentioned earlier, the Like button triggers many subsequent actions and associations among participants of the network (the features of the social media platform) such as the placement of the post on other Twitter users' timeline in the network, several invisible records in Twitter's database that store the information, and so on. After the post is Liked, the user who liked the post cannot re-like the post (only deactivate the like button), so their relationship with the post changes. Throughout this analysis, ANT allows treating human and non-human participants of the network equally. This makes it a fitting approach to analyze case studies for this research. The next section describes the use of Actor Network Theory to analyze each of the case studies in more detail.

\subsubsection{Actor Network Theory}
Actor Network Theory (ANT) was used to outline the process of network creation as a result of audience interactions which enables technical communicators to study audiences and brings a transformation in technical communicators' roles. This section begins by introducing the ANT approach. It then focuses attention on introducing the concepts of network actors, control, and the four moments of the sociology of translation. By referring to previous studies informed by ANT, the following section outlines and describes the process of analysis used and the expected outcome of the process as applicable to each case study. The last section discusses potential limitations due to the controversies and challenges of using ANT, reliability concerns, and ways of addressing them.

It is important to understand that ANT is neither a theory nor a method being applied directly to study case studies for this research. ANT is instead an analytic framework that supports other theories. All case studies are assumed to be knowledge networks as mentioned in multiple instances in this and the previous chapters. Other theories such as social network analysis \cite{grandjean2016social, freeman2004development} or rhizome theory \cite{felix1987thousand, honan2007writing, clarke2013becoming} can also be used to analyze the networks qualitatively. ANT does not stand in opposition to other theories. It instead provides a tool to understand the complexity and meaning of the actors in the network who are performing their roles, and by analyzing them in real-time reveals other actors in the process. The results thus do not suggest the structure of the network, but rather demonstrate how audiences' participation and technical communicators' roles are translated and how they impact knowledge networks that they are part of.

\subsubsection{Background}
ANT is a social theory framework that originated in the field of the epistemology of science. ANT was adopted by Michael Callon and Bruno Latour (e.g. \cite{callon2007some, latour2005reassembling, latour1988write, latour1999recalling} to study the sociology of science and technology. Initially, ANT was concerned with how scientists achieved the support of others for their propositions about scientific facts, and how power and resources were acquired to perform their work \cite{van2003digital}. This network theory puts emphasis on the concept of non-human actors and the interplay between entities with agency, human and non-human actors, as well as relations formed by negotiations and interactions to produce stable, heterogeneous networks of actors with aligned interests \cite{law1992notes}. By tracing the transformation of these heterogeneous networks, ANT explores how these networks of actors and their relations emerge, are maintained, and compete with other networks of aligned interests \cite{tatnall1999actor}. Actor-Network Theory can therefore be used to characterize knowledge networks in which audiences participate to explore their roles, their placement in the network (which determines their associations, relationships and proximity to other actors), how they generate effects such as smaller groups within larger organizations, inequalities, hierarchies, and dependencies. The actors that make up a system play an important role as they help give meaning and social explanations based on interconnections with each other, as opposed to looking for self-contained meaning to the independent actors. So the first step is to identify actors. All ANT principles and concepts rely heavily on the definition of actors.

There have been numerous studies that use ANT to examine the implementation of projects where the social aspect of knowledge development has been traced, the role of technology is studied in facilitating the success or failure of project development, and so on. These studies have shed new light on how projects are implemented. For example, Swarts' study reveals the relationships between functional and rhetorical knowledge to establish how technological literacy reflects a complex and distributed social \cite{swarts2011technological}, \textcite{albrechtslund2013spaces} analyze three empirical examples to follow traces of participation in a broad range of everyday surveillance spaces, and \cite{potts2019boycotting} uses ANT to argue that everyday citizens are often eager to participate in conversations surrounding emergencies but face challenges in doing so because of a variety of barriers in access and interface design; ANT is used to gain an understanding, formulation and stabilisation of groupings, referred to as networks of data sets, in the analytics of big data at a strategic level in an environment by \textcite{Iyamu_2018}, while \textcite{islam2019blockchains} build on ANT to investigate blockchain split as a translation process, and employ case study methodology to examine Bitcoin splits. Although these studies are relatively new, ANT for analyses work has been used for over three decades, primarily to interrogate social, scientific and technological networks \cite{horowitz2012translation}. The theory is scalable and flexible in that it can be combined with other approaches or techniques for analytic purposes. Therefore, I consider ANT to be appropriate for gaining an understanding, formulation and stabilisation of networks of knowledge production in the case studies for this research viz. a user's pull request on GitHub, content analytics data about audience behavior, feedback mechanism used for error reporting.

\subsubsection{Tracing network actors}
Once it was established that human and non-human actors will be identified starting from the "point of user interaction until a stabilized network was created", the process was guided by three main principles that underlie the ANT approach: generalised symmetry, agnosticism and free association \cite{callon1986sociology}. Firstly, the principle of generalised symmetry is reflected in the way ANT defines actors \cite{van2003digital}. According to this view no distinction between human and non-human actors should be made. Both should be analysed in the same terms without making any discrimination \cite{callon1986sociology, law1986heterogeneity, law1987technology}. ANT invites us to not impose preconceived analytical categories on the problem at hand, but remain open and let the actors themselves reveal the categories we're studying. In so doing, this principle maintains that both human and non-human actors have the ability to take actions, and can be anyone or anything \cite{law1986heterogeneity}. Actors are defined by Law \cite{law1987technology} as individual entities who take actions through which they can “exert detectable influence on others”. Actors are traced from the moment of audience’s interaction with the knowledge platform that creates content – this moment reveals the primary actor – and until the content gets transformed owing to user(s) interaction. In any analysis, the actors’ relationships and the way they explain their worlds must be allowed to fluctuate. The second and third principles require researchers to systematically avoid censoring any interpretations provided by the actors studied when they describe their own actions or other actors \cite{callon1986sociology}, even when the interpretations can differ from observers, including the researcher \cite{law1986heterogeneity}. The second principle, ‘agnosticism’ suggests that the observer of the actor network needs to be impartial, and requires that all interpretations be unprivileged. The third principle, ‘free association’ requires the abandonment of all a priori relationships that could be assumed to exist between human and non-human actors \cite{callon1986sociology}. Since this research uses a mixed-methods approach, there was a higher chance for the researcher to get influenced by the interview data before analyzing case studies and have preconceived notions about who the participants in the network are, based on the interview data rather than observations of case studies. To prevent that, data from case studies was separated from the interview data. The interviews only yielded ideas for the kinds of case studies that might be viable. The absence of data related to case studies from the interview process, eliminated their impact on later investigations. Rather than imposing relationships upon the actors, the researcher focussed on the translation process. The principle of generalisation was used to treat all actors equally, regardless of their position (order in the translation process) and their ability to take actions (primary or secondary).

As mentioned earlier, to trace each case study, the researcher started with the primary actor. Other actors were added to the list based on their effect on the network and role in the translation process. Actors roles are determined by the associations they have with other actors. For example, if they influence other actors to perform certain actions, or undergo negotiations to stabilize the network, and so on. Understanding associations is incremental to 'following' actors. The next section describes a strategy to trace associations that lead to identification of actors beyond the primary actor.

\subsubsection{Tracing associations in actor-networks}
While actors are individual entities, actor-networks, or simply networks, are groups of actors: networks of heterogeneous materials linked with one another through different relationships, and whose resistance has been overcome \cite{law1992notes}. For a new network to emerge, the primary actor who has the main control when network tracing begins, and those exercising control on its behalf - needs to enrol other actors in order to align their interests, and weaken the presence of other actors that might act against the goals of the network to ultimately stabilize the network. The control exerted by the primary actor determines in which direction will the network be traced. To understand the process of translation or of tracing (adding) actors to the existing network, we need to first understand what \textit{control} means in ANT.

\textit{Control} is being able to persuade other actors to perform specific roles. To exercise control over others, controlling actors must develop different strategies through associations that may involve negotiations with other actors in the network. A controlling actor cannot exercise control alone, as Law highlights when discussing how the process of transformation of networks is achieved – Law states that "Texts of all sorts, machines or other physical objects, and people, sometimes separately but more frequently in combination, seem to be the obvious raw materials for the actor who seeks to control others at distance (\cite{law1986heterogeneity}, p. 255)." However, those ‘raw materials’ needed by the controlling actor to exercise control and those aimed at being controlled, more often than not, pose different sorts of resistance and struggle \cite{law1992notes} that can come from different sources and at different moments during a translation process. The controlling actor might create a successful actor-network only when all other actors are successfully persuaded. While networks are continuously evolving and transforming in ANT, usually certain entities take control, even if temporarily, to create temporary actor-networks \cite{callon1986sociology, law1986heterogeneity}. Those playing the role of the controlling actor develop different strategies to drive the translation in order to enrol and mobilise other actors \cite{blackburn2002project}. During a successful translation, those being controlled are obliged to remain faithful to the objectives of those who control, and those exerting control are given the right to represent those mobilised \cite{callon1986sociology}. Sometimes, some actors may not be able to be persuaded (and therefore enrolled) because their roles are not visible, needs are not met, their roles have not been communicated, and so on. In such cases, spokespersons play a critical role. When changing the state of an actor, the spokespersons can express what others say and want in their own language. Moreover, a process of translation not only entails some actors establishing themselves as spokespersons, but also requires processes of displacement to take place. In addition to spokespersons' playing their part, negotiations can take place between the controlling actor and those who they seek to enrol. For example, in the case of product documentation platforms, the platform infrastructure needs to be designed in a way that audiences and technical communicators can control it and their movements can be traced through communication patterns to trace changes (edits). In this case, infrastructure refers to the technological environment in which user interactions occur, and which holds the network together. Once the controlling actor has translated the interests of others to achieve its aims, the actor-network becomes stabilised. This means that in the example mentioned, infrastructure becomes the controlling actor, bringing all actors together in a network to stabilize it. Technical communicators can be spokespersons of how the infrastructure gets designed. Audiences need to interact with infrastructures to become associated with the (knowledge) network that may be formed and stabilized as a result of this process.

While tracing networks it was found that there could be infinite number of associations among each of the network's actors that could stretch the networks in all directions. Actors that can be classified as belonging to technological infrastructures, usually black-boxed, have the ability to breakdown into tiny units. The black-boxing ability itself enables grouping of those tiny units into larger groups. The decision of choosing actors from the list of tiny units or grouped systems was to be dictated by the possible associations and the roles that those associations brought to light. An exhaustive list of associations was therefore created before beginning to trace the network and used to enrol new actors (units or groups). Following is the list of associations that was coded and used such that it could be applied to all three cases:

There are two important considerations for stabilized networks: first, they can be black-boxed if all the actors have not been identified; and second, the network always has the potential to change and evolve since the relationships linking the actors of the network may be weakened, or because other actors external to the actor-network can impact its stability. Only when a network is formed of a range of durable materials can it be seen as relatively stable \cite{law1992notes}. To analyze such ever-changing networks, the process of translation is studied. The sociology of translation helps understand how networks emerge, stabilize, and get transformed. A translation process entails four interrelated moments: problematization, interessement, enrolment and mobilisation \cite{callon1986sociology}. During a successful translation, those being controlled are obliged to remain faithful to the objectives of those who control, and those exerting control are given the right to represent those mobilised \cite{callon1986sociology}. The process of translation is not linear. In this study, it helps trace actors based on their presence, control, and role in the transformation of content from the point of user (audience) interaction.

\begin{enumerate}
  \item \textbf{Problematization}: This process involves finding actors that go through the ‘Obligatory Passage Point' (OPP). Asking questions will give you a list of actors and also the links between them. In the ‘problematization’ stage, one or more key actors attempt to frame the nature of the problem in their own terms \cite{tatnall2002using, sarker2006understanding}. They also identify and involve a number of actors whose roles and relationships configure an initial problem-solving network \cite{linde2003actor}. At this stage, the identities of other actors must be defined. Once the controlling actor configures an initial actor-network \cite{linde2003actor}, it is crucial for it to define the problem in its own terms by establishing it as an OPP through which it renders itself as indispensable \cite{callon1986sociology}. Thus, by establishing an OPP the controlling actor imposes its view on others. It thus suggests that the problems of others would only be resolved by passing through the OPP \cite{law1986heterogeneity}. Should other actors wish to pass through the OPP, they first need to modify their current interests and to align them to those of the controlling actor. Only by imposing its propositions as OPPs, will the controlling actor be successful.
  \item \textbf{Interessment}: The second moment of translation is ‘interessement’. It involves checking what the actors are interested in. They help in stabilizing the network and addressing the concerns of the actors in the network. Interessement embraces a group of actions by which an actor interests others sufficiently to agree with its proposal \cite{callon1986sociology}. Through this process, those supporting the emerging network incite actors into fixed places \cite{tatnall2002using}, and weaken the influence of other actors that may disestablish the developing network \cite{linde2003actor}. Methods used for this process of checking the actors' interests are called devices of interessment. Independent of the devices, the final goal is to isolate those being enrolled by impeding any other possible alliance that may challenge the legitimacy of the OPP. Finally, for interessement to be successful, it needs to achieve enrolment (\cite{callon1986sociology}, p. 211).
  
  \item \textbf{Enrolment}: The process of translation is not over once the actors have been identified as interessement does not necessarily lead to successful alliances. It needs to be reinforced by enrolment \cite{callon1986sociology}. The process of enrolment consists of “negotiations, trials of strength and tricks that accompany the interessements and enable them to succeed” (\cite{callon1986sociology}, p. 211). If the necessary alliances are to succeed, a definition of roles played by those actors to which control is being exercised is devised according to the scheme proposed in the OPP \cite{linde2003actor, law1986heterogeneity}. The spokesperson assigns roles and makes sure that actors are satisfied with those roles. This process is called enrolment. While doing so there might be arguments (dissidence) or complaints against the spokesperson. For a successful network, a majority of actors need to be satisfied which means that they should support the spokesperson’s stand on situations and arguments.
  \item \textbf{Mobilization}: The final step is when the spokesperson sends the message across. The actors are mobilized by the spokesperson who was able to clearly articulate the concerns of the actors, the actors are left with no choice but to agree and follow the spokesperson.
\end{enumerate}

The above four-stage translation process implies that a) Network represents the structure of interrelationships related to the matter at study. Networks are built and torn through a series of actors engaging in interest work, enrolment, alignment and translations \cite{law1992notes}; and b) Organisations and their components are effects generated in multiple interactions, rather than existing merely in the order of things \cite{latour1987science, latour2005reassembling, law1992notes}. The four-stage translation process of how an actor joins a network is not thought to be smooth sailing. First of all, as argued by (\cite{law1992notes}, p. 384), as actors are themselves actor-networks consisting of heterogeneous actants (\cite{law1992notes}, p. 384), the translation process becomes complicated. These translations involve a complex series of negotiations within the networks whereby identities are fought over, roles are ascribed, and power relations fixed. It is in this sense that ANT can be described as a 'relationalist' theory for the identities of actors or actants are determined within the networks in relation to one another \cite{law1992notes}.

\subsection{ANT in action}
From an empirical and analytical point of view, ANT researchers are interested in how actor networks are assembled and stabilised (maintained in place). \textcite{callon1986sociology} is a good example that demonstrates how actor networks are interested in how autonomous actors are enrolled in new programs of activity and prevented from following their own designs. At the same time, it shows \textcite{law1992notes} argument of how actor networks are also interested in how actor networks stabilize over time, become black boxed, punctualized, or part of the taken-for-granted fabric of the social. This study benefits from using Actor Network Theory as an analytical framework to both identify actors, actor networks, and also to understand what draws them together to make a functioning network audience for knowledge production. The four-stage translation process \cite{callon1986sociology} provides a framework in guiding discussions of the complex processes involved in identifying the roles of audiences, infrastructures and technical communicators in assembling an actor-network configuration from heterogeneous entities involving negotiations, emplacement, and displacement of some or all actors.

\textcite{callon1986sociology} proposition to ‘follow the actors’ helped foster and discover the actor networks that constitute each of the aforementioned case studies. For this study, actors were traced by first establishing a focal actor and following the actor to unravel further connections as adapted in \textcite{callon1986sociology}. This process was implemented in line with Gold's proposition of following actors until a saturation point is reached and no additional new data is found in the case study (\cite{golds1997healthy}, p. 392). Gold’s suggestion acts as a guide on which actors to follow and how far to trace the actors in the process of translation.

\subsubsection{Creating a pull request on GitHub (CS 1)}
Several participants in this study identified the use of collaborative platforms like GitHub as a means to solicit user feedback. A pull request (PR) from Microsoft's product documentation titled "Added procedure to open Performance Monitor \#2562" or "CS 1", hosted using GitHub, was used for this research for analysis as a case study. While creating a pull request, users need to first sign into the platform (GitHub) which helps identify who created it. Organizations who solicit such feedback generally provide instructions to help users format the feedback and add all the required information in the PR that is necessary to create meaningful and useful content. Users can decide to follow the instructions to create the PR, add content, and submit it. Users can also provide qualitative feedback, such as comments, to make their PR easy to understand. After making the desired change, users push the PR so that it can be merged with the main documentation. In CS 1, thethales created the PR (https://github.com/MicrosoftDocs/windows-driver-docs/pull/2562) to add a small snippet of content – a new procedure to open Performance Monitor (https://github.com/MicrosoftDocs/windows-driver-docs/pull/2562/commits/6be04e06cb2335ae0912025ba52caec0c4eb8241). The PR was assigned to the designated official DOMARS by Ted Hudek, another user associated with Microsoft, and handled by DOMARS until it was merged with the original content that appears on the public facing documentation site (https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/determining-whether-a-leak-exists). To study this case using an ANT approach, the complexity of the case must be understood. Audience that includes the user thethales contributes to the documentation thus forming a network with other participants (Microsoft personnel) and GitHub infrastructure who become part of the network. If the personnel had decided that the content or feedback is not relevant, they had the power to close the PR without making any changes. According to ANT, all components of a network, such as objects, ideas, processes, and any other relevant factors, are considered as important as humans in creating social situations. ANT analysis and decisions made to to trace all the actors and associations that form the knowledge network is discussed in the next chapter.

\subsubsection{Collecting data from web analytics tools (CS 2)}
To understand audience behavior and analyze information consumption, companies pull abstract data and conduct research to extract knowledge using different tools. This research uses data retrieved from various tools used by company ABC to understand their audience’s behavior. Three main tools used for collecting analytical data are Google Analytics (GA), Pendo, and Salesforce. Results from analyzing data from these three platforms are triangulated by technical communicators to gain insights about their users. As users navigate through online documentation, GA records their behavior. As users use the product, Pendo tracks the features used most frequently. Finally, although Salesforce data is entirely managed by the organization, content created to record user actions of requesting help from support teams, leaving feedback for the service, and ability to resolve problems after the call has been completed, all contribute to significant data that gets stored on the platform. Without infrastructures in place, user data will not be generated for analysis. This case study also analyzes the network of actors that gets formed as a result of multiplicity of data points and dependencies on each other.

\subsubsection{Reporting errors in documentation (CS 3)}
The third case study analyzes a method of reporting error that can be accessed by users. Tools that record customer feedback allow organizations to use a black-boxed task allocation and bug tracking framework. When a user posts a feedback comment (on the documentation site) or creates an Issue (using a platform like GitHub), it goes into the issue tracking system. In this case, I analyzed an issue created by a user Xunzhuo on IBM's documentation platform GitHub (https://github.com/istio/istio.io/issues/8888). Similar to content modifications, to report an error, users have to create issues. In this case, GitHub was the platform used to report errors. The journey from when user Xunzhuo created the issue - the issue being the primary actor – to when the issue was handled by an employee of the organization (IBM) was tracked to study this case. I also came across bots that are used by IBM's documentation platforms to assign tags and keywords to the content created on the platform. I analyzed all the actors that form the knowledge network for communicating problems in the documentation, and also investigated the translation of the error from an error message, to adoption in the documentation.

Analyzing these cases as networks enables us to understand activities among different components of the network, such as information coordination, transfer of control and agency among those components, the act of combining components with each other, and so on. This use of ANT to study information coordination and network fluidity has gained attention by other technical communication researchers. This study makes use of the ANT concepts to identify actors in order to trace how they create information from raw data, technological systems, and by associating and dissociating from the network at particular instances of time. This move is different from observing static systems and instead urges technical communicators to look at flexible models of knowledge creation.The following questions were used to analyze the flexibility nature of knowledge networks that get formed in each of these cases.
\begin{enumerate}
  \item Which actors are participating in these networks?
  \item What activities are being carried out by the actors during content development processes?
  \item What kinds of relationships are built among the actors exercised while carrying out these activities?
  \item Can we identify how power is being exerted and how agency is being transferred from one actor to another?
\end{enumerate}

These questions allow analyzing each case through a chronological lens. Secondly, they help simplify the network to look at independent actors and their relationships. To make some actions possible, the network reconfigures and these questions help in understanding how and when these reconfigurations are taking place.

\subsection{Limitations of methodological framework}
While the study relies on ANT to derive novel interpretations and insights of the knowledge networks, associations, dependencies, and interconnections between actors, and an adaptable system to track the translation process for content, it also becomes necessary to acknowledge the critiques and potential challenges of some of ANT’s controversial claims. This section highlights the typical criticism that using ANT would bring to this research and how to overcome that.

First, critics argue that when using ANT, there is a tendency to adopt an objective stance; that is, the vocabulary that ANT analyses tend to use fails to match the descriptions and explanations that research participants would provide themselves \cite{murdoch2001ecologising}. In adopting this position, Whittle and Spicer \cite{whittle2008actor} note that those taking ANT as their theoretical lens seem to suggest the theory is capable of offering a superior or expert view that implies members’ explanations might be incomplete, naive, or wrong. Whittle and Spicer \cite{whittle2008actor} also argue that in an attempt to find parallels with the four step process of translation, researchers may eliminate some other perspectives resulting in one common truth that will appear in the result. To avoid this from happening, this research is based upon the belief that: 1) reality is a process of construction and interpretation in which the researcher plays a key role; and 2) the potential of multiple other interpretations is not only possible but also desirable. Second, rather than engaging in a deductive approach to test or refute the conceptual tools provided by ANT, these analytical devices are adopted as sensitising ideas to explore the phenomenon under investigation in the light of the case studies approach. The study is meant to lead to a new conceptualization of the audience rather than to prove that an already existing theory works.

Another relevant controversy has been around the “flat ontology” of ANT \cite{whittle2008actor}. This refers to low attention ANT pays to how broader social structures influence the local \cite{walsham1997actor}. Those arguing against ANT suggest that its ontology tends to neglect the regulating role that social structures play in shaping and giving consistency and continuity to relations developed among actors. This phenomenon is acknowledged and steps are taken to prevent its impact on the study. These steps include: first, generating a context that is used to set up each case so that actors inside and outside the organization with differential power are clearly visible. Second, the context provides a narrow lens to scrutinize the contents of each case study, but at the same time, using the content transformation process as a driving rule provides a set of boundary conditions which then enable the tracing of actors not too broadly, but as a part of a specific, and restricted system (documentation). Latour has suggested that ANT allows moving between different levels of analysis, thus assisting with the investigation of both the macrostructures and the microstructures using the same methodological approach. This viewpoint is also supported by \textcite{callon1981unscrewing}, who argue that “all differences in level, size and scope are the result of a battle or a negotiation” and can be studied through ANT.

Finally, the most controversial debate surrounding ANT, is the principle of general symmetry. The basis of this principle argues that humans and non-humans must be seen as active entities. Accordingly, technologies must not be seen as neutral, or inert, but as actors that cannot be taken for granted. \textcite{collins1992epistemological} were among the first to criticise this principle, arguing that the symmetrical treatment to humans and non-humans is in tel intellectually and morally problematic because it removes humans from their pivotal role \cite{munir2004discontinuity, whittle2008actor}. However, those supporting ANT suggest that the symmetrical stance seeks to overcome the over-emphasis given to human agency that is favoured in sociological studies. In relation to this, this research adopts a stance that acknowledges that the extreme position of symmetry is difficult. However, it is also acknowledged that assuming a symmetric stance towards humans and non-humans has the potential to examine critically the key role of technology that supports the network of audiences as well as the network of infrastructures that control audience movements. In so doing, this research is aligned to the aim proposed by \textcite{callon1981unscrewing} of using this principle as a means to develop a ‘symmetric metalanguage’ to refer to humans and non-humans with an ‘unbiased’ vocabulary, and to adopt it as an analytical stance, not as an ethical position \cite{law1992notes}.

\subsection{Validity and reliability}
\textcite{law2002objects} argues that whilst entities in their broadest sense are usually conceived of as having stability and uniqueness, in contrast ANT advocates that they are a result achieved when different heterogeneous elements are continually assembled together (see also \cite{callon1986sociology, law1999after}). using this assumption, one can say that the case studies used for this research are never completely stable and cannot be used to establish generalized theories, in this case audience conceptualization. To that effect, this research relies on other methods to achieve validity and reliability.

Although choosing ANT as the theoretical framework forced the researcher to approach case studies from a network perspective, the view was only used to study the social structure of audiences. A social network analysis would have fallen short as it primarily focuses on human actors. This was also driven by the fact that low attention is paid to how audiences come from social structures, and that they not only form communities but also networks as they become involved in the process of content production. ANT helps focus on infrastructural elements of not only the knowledge network, but also the way audiences get involved and become part of the network for knowledge production. The focus on human and non-human actors ensures that all parts of the network system are adequately traced. When technical communicators work with documentation systems, they are responsible for not just information production, but also making sure that users are able to access it in the most effective manner. They rely on content strategy and design thinking approaches to do so. Such approaches rely on infrastructures and their abilities to engage the users as well as participate in knowledge making. Therefore, analyzing infrastructural elements is useful for validating the impact of the findings of this research.

To ensure that the results are reliable, the analysis of case studies was reviewed by one academic scholar and one practitioner. Both of them looked at each case study objectively. The academic reviewer made sure that the cases were clearly depicted as networks. The practitioner reviewer corroborated with the network setup based on their practice and working environment depicted through the network described for each case, as well as confirmed the results of the research as critical for the field.

The research also uses results from analyzing participants' interviews to corroborate the insights from analyzing case studies. The research responds to two research questions; first, to understand whether audience contributions provide insights about audiences. Participant interviews helped the researcher build a preliminary hypothesis about this which will be validated through analysis of the case study. Second, the study points out to the changing roles of technical writers. While tracing actors and their roles in the translation, some of the roles of technical writers were recorded. Those were then compared to the feedback received during interviews.

The next chapter discusses the results of analyzing the case studies. Each case study is depicted using network visualizations and described in detail in terms of how networks are established, maintained, and contribute to audience analysis processes. Reviewer feedback will also be shared along with the discrepancies between the researcher's understanding of the case as compared to the practitioner reviewer's and what steps were taken to achieve reliability of findings.
